const fs = require('fs');
const path = require('path');
const axios = require('axios');
const { Readable } = require('stream');
const { openai } = require('../config/openaiConfig');
const { logger } = require('../utils/logger');

exports.transcribeAudio = async (req, res, next) => {
  try {
    if (!process.env.OPENAI_API_KEY) {
      return res.status(500).json({ error: 'Server missing OPENAI_API_KEY. Please set it in .env and restart the server.' });
    }
    if (!req.file) {
      return res.status(400).json({ error: 'No audio file uploaded' });
    }
    
    const audioPath = path.resolve(req.file.path);
    const originalFilename = req.file.originalname || 'audio.mp3';
    
    try {
      // Some OpenAI SDK usages require the multipart filename to include the extension
      // Multer stores files with autogenerated names (no extension). To ensure the
      // multipart upload contains the original filename (and extension) we copy the
      // uploaded temp file to a new temp path that includes the original filename,
      // then stream that file to OpenAI. This avoids adding new dependencies.
      const uploadsDir = path.dirname(audioPath);
      const safeOriginal = originalFilename.replace(/[^a-zA-Z0-9._-]/g, '_');
      const tempPath = path.join(uploadsDir, `${Date.now()}_${safeOriginal}`);

      // Copy the multer temp file to a new file that includes the original filename
      fs.copyFileSync(audioPath, tempPath);

      // Create a read stream from the temp file (stream.path contains filename)
      const audioStream = fs.createReadStream(tempPath);

      // Whisper API call - stream with filename in path helps OpenAI detect format
      const response = await openai.audio.transcriptions.create({
        file: audioStream,
        model: 'whisper-1',
        response_format: 'json',
        temperature: 0.2,
        language: 'en'
      });
      
      // Clean up temp files (original multer temp + our copied temp)
      fs.unlink(audioPath, () => {});
      fs.unlink(tempPath, () => {});
      
      // Response shape may vary; be defensive
      const transcript = (response && (response.text || (response.data && response.data.text))) || '';
      return res.json({ transcript });
    } catch (openaiError) {
      // Clean up temp files if OpenAI call fails
      try { fs.unlinkSync(audioPath); } catch (e) {}
      try { fs.unlinkSync(tempPath); } catch (e) {}
      throw openaiError;
    }
  } catch (err) {
    logger.error('Transcription error:', err);
    
    // Provide more helpful error message for unsupported formats
    if (err.message && err.message.includes('Unrecognized file format')) {
      return res.status(400).json({ 
        error: 'Unsupported audio format. Please use one of: mp3, mp4, mpeg, mpga, m4a, ogg, opus, flac, wav, or webm',
        details: err.message
      });
    }
    
    return next(err);
  }
};
